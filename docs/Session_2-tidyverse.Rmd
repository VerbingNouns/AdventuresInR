---
title: "Session 2: Tidyverse"
output:
  html_notebook:
    toc: yes
    toc_depth: 2
    df_print: paged
    number_sections: true
    toc_float:
      collapsed: false
---

> **Data manipulation and visualisation**

# Tidyverse functionality

Tidyverse is a package, or a set of add-on tools, that you can optionally use in R to easily and clearly process and visualise your data. In the tidyverse, there are a number of included packages. You do not need to use them all, nor do you need to load them all, but for simplicity's sake, it's easier to load the whole thing and then not worry about it.

```{r}
#install.packages(c("knitr","tidyverse"))
library(tidyverse)
```

How would you write the base R function `head(quakes)`?

```{r}

```

The verb `count()` counts how many attestations there are of each level in the specified column.

How many attestations of each type of `mag` in `quakes`?
```{r}

```

What does `quakes` look like?
```{r}

```


# Processing into tables

Before we start learning anything about our data and results, we need to process and organise the data.

## Add columns

How can you make a new column?
```{r}

```

Duplicate `mag` into `magFct` for `quakes`:
```{r}

```

Create a column in `quakes` that calculates the `depth` of the quake divided by the number of `stations` reporting:
```{r}

```

### Case when

Tidyverse tries to reduce the need for "for loops". Instead of going line by line through a dataset to determine what contingent behaviour to perform. The for-loop behaviour is time and energy intensive on large datasets. That's why `case_when` is so powerful.

Here's an example of how one might create a column that translates the values in `mag` in `quakes` to a word:
```{r}
# == equivalent to
# > greater than
# < less than
# >= greater or equal
# <= less or equal
# != NOT equivalent to
# & and
# | or

quakes %>% 
  mutate(magText = case_when(mag<"5" ~ "four",
                             mag>="6" ~ "six",
                             TRUE ~ "five"))
```


Now, how would you create a column in `quakes` that groups magnitude into "low", "medium" and "high"? What if we want a fourth category?
```{r}

```

We can also use this to perform other sorts of contingent calculations.

Create a column that adds 10 to `long` when it is above 175 and subtracts 10 from `long when it is below 175:
```{r}
quakes %>% 
  mutate(???  = case_when(??? ~ ???,
                          ??? ~ ???))
```

## Filter

If we only want to look at magnitudes between 4.5 and 4.9 from `quakes`, we can filter the dataset (which is like subsetting):
```{r}

```

## Group and summarise

What if we want to get aggregate values from our dataset, rather than looking at it as a whole?

**`group_by`** is a verb that flags certain columns for operations down the line. **`summarise`** checks which columns are flagged and performs operations based on the permuations of values in those columns.

What happens when we use `group_by` by itself?
```{r}
quakes %>% 
  group_by(mag)
```

How many observations are there per "level" of magnitude?
```{r}

```

We can use `group_by` and `summarise` to do a lot more than just count:
```{r}
# mean value of `stations` for `groupMag` magnitudes
quakes %>% 
  mutate(groupMag = case_when(mag ??? ~ "low",
                              mag ??? ~ "medium",
                              mag ??? ~ "high") %>%
                    recode_factor(`low`="low",
                                  `medium`="medium",
                                  `high`="high")) %>% # this turns our character vector into an ordered factor
  group_by(???) %>% 
  summarise(???)
```

Let's create a table of the means, standard deviations, and standard errors for both stations reporting and depths grouped by magnitude:
```{r}
quakes %>%
  group_by(???) %>%
  summarise(number = ???,
            stationMean = ???,
            stationSD = ???,
            stationSE = ???,
            depthMean = ???,
            depthSD = ???,
            depthSE = ???)
```

(This is VERY useful for graphing and creating summary statistics tables!)

# Processing Text

```{r}
shake <- read.csv("../data/Shakespeare_data.csv", as.is = TRUE)
```

What is the structure of this dataset?
```{r}

```

## Select and transmute

Select allows you to specify which columns to keep.
```{r}

```

Or which to get rid of.
```{r}

```

Transmute allows you to select which to keep while also renaming them.
```{r}

```

## Unite and separate (text)

The column `ActSceneLine` can be split into three columns to be more useful:
```{r}

```

Create a new column that combines the play's name with the act number:
```{r}
shake %>% 
  separate(???) %>% 
  mutate(???) %>% 
  unite(???)
```

More examples [here](https://tidyr.tidyverse.org/reference/separate.html).

## Tidytext: Unnest

`unnest_tokens` automatically creates a new row for each word from a text column:
```{r}

```

Combine this with our new column structure and remove unwanted columns:
```{r}

```

Filter this dataset so it's only spoken lines, no stage directions:
```{r}

```


